import re

from datetime import datetime
from typing import Pattern, AnyStr
from util.schema import Schema


LOG_PATTERN: Pattern[str] = re.compile(
    r"(?P<remote_addr>\S+) \S+ (?P<remote_user>\S+) \[(?P<time_local>[^\]]+)\] "
    r'"(?P<request>[^"]*)" (?P<status>\d{3}) (?P<body_bytes_sent>\S+) '
    r'"(?P<http_referer>[^"]*)" "(?P<http_user_agent>[^"]*)"'
)


def load_data(fp: str) -> list[str]:
    """
    Function to load entire .log file by using readlines() built-in.
    :param fp: filepath to open as str
    :return: lines as list of str
    """
    if fp is None:
        raise FileNotFoundError("Couldn't resolve filepath input to preprocessor")

    with open(file=fp, mode="r", encoding="utf-8") as f:
        lines: list[str] = f.readlines()
        return lines


def build_schema(log: str) -> Schema | None:
    """
    Function to map an individual NGINX log line to the defined schema using regular
    expression pattern matching. Assumes NGINX default combined log format.

        Pattern components:
      - (?P<remote_addr>\S+)         -> client IP address
      - \S+                          -> ident field, ignored
      - (?P<remote_user>\S+)         -> authenticated user, or "-" if none
      - \[(?P<time_local>[^\]]+)\]   -> timestamp string inside [ ]
      - "(?P<request>[^"]*)"         -> full HTTP request
      - (?P<status>\d{3})            -> HTTP status code (3 digits)
      - (?P<body_bytes_sent>\S+)     -> size of response in bytes, or "-"
      - "(?P<http_referer>[^"]*)"    -> HTTP Referer header, or "-"
      - "(?P<http_user_agent>[^"]*)" -> User-Agent string

    :param log: line of the file to parse as str
    :return: a schema of the line
    """
    if not log.strip():
        print("Empty line encountered, skipping")
        return None  # may wanna change this

    match = LOG_PATTERN.match(log)
    if not match:
        raise ValueError(f"Could not parse log line: {log}")
    log_dict: dict[str, AnyStr] = match.groupdict()

    dt = datetime.strptime(log_dict["time_local"], "%d/%b/%Y:%H:%M:%S %z")
    iso_ts = dt.isoformat()

    return Schema(
        remote_addr=log_dict["remote_addr"],
        remote_user=None if log_dict["remote_user"] == "-" else log_dict["remote_user"],
        time_local=log_dict["time_local"],
        timestamp=iso_ts,
        request=log_dict["request"],
        status=int(log_dict["status"]),
        body_bytes_sent=(
            None
            if log_dict["body_bytes_sent"] == "-"
            else int(log_dict["body_bytes_sent"])
        ),
        http_referer=(
            None if log_dict["http_referer"] == "-" else log_dict["http_referer"]
        ),
        http_user_agent=(
            None if log_dict["http_user_agent"] == "-" else log_dict["http_user_agent"]
        ),
    )


def process_logs(logs: list[str]) -> list[Schema]:
    """
    Function to accumulate the processed schemas into a list of schemas.
    If an empty log is detected, it will skip that line and move onto the
    next.
    :param logs: a list of strings representing lines of a .log file
    :return: a list of logs represented as schemas
    """
    processed: list[Schema] = []
    for log in logs:
        processed_log: Schema = build_schema(log)
        if processed_log is not None:
            processed.append(processed_log)
    return processed


def group_by_user(logs: list[Schema]) -> dict[str, list[Schema]] | None:
    """
    Function to map each user to a list of their associated logs by
    mapping each remote_addr to a list of all logs containing that
    remote_addr. If the input is empty, the function will return none.
    :param logs: the list of Schemas to be grouped by remote_addr
    :return: dict[remote_addr : list of associated logs] or None
    """
    if not logs:
        return None

    grouped: dict[str, list[Schema]] = {}
    for log in logs:
        remote_addr: str = log["remote_addr"]
        if remote_addr not in grouped:
            grouped[remote_addr] = []
        grouped[remote_addr].append(log)

    return grouped


def print_list(schemas: list[Schema]) -> None:
    """
    Debugging function to clean output of the list of schemas for
    visual inspection. Prints which log it is interpreting based on
    line number in the given file. This function was generated by GPT5.
    :param schemas: list of schemas to be printed
    """
    for i, schema in enumerate(schemas):
        print(f"Entry #{i + 1}")
        for key, val in schema.items():
            print("{} : {}".format(key, val))
        print("======================================================")


def print_output(users: dict[str, list[Schema]]) -> None:
    """
    Debugging function to clean the output of the grouped dictionary
    of schemas. Prints which user it is interpreting based on the value
    of the current remote_addr. This function was generated by GPT5.
    :param users: grouped dict to be printed
    """
    for i, (remote_addr, logs) in enumerate(users.items()):
        print(f"Entry #{i}")
        print(f"User: {remote_addr}")
        for log in logs:
            print(log)
        print("======================================================")


def preprocess() -> dict[str, list[Schema]]:
    path: str = "../data/access.log"
    logs: list[str] = load_data(fp=path)
    processed: list[Schema] = process_logs(logs=logs)
    grouped: dict[str, list[Schema]] = group_by_user(processed)
    return grouped


if __name__ == "__main__":
    output: dict[str, list[Schema]] = preprocess()
    print_output(output)
